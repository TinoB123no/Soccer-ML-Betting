# -*- coding: utf-8 -*-
"""SoccerReinforcement.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aeSRVMSUpbFJfWt09M21_fc53jiqG5Ui
"""

# !pip install stable-baselines3
# !pip install understat


# !pip install cloud-tpu-client
# !pip install torch-xla
# This setup is for Colab with PyTorch and torch_xla (for TPUs)
# !curl -O https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py
# !python env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev


import gym
from gym import spaces
import numpy as np
from stable_baselines3 import PPO
from stable_baselines3.common.env_util import make_vec_env
import torch
import torch.nn as nn
# import torch_xla
# import torch_xla.core.xla_model as xm
# import torch_xla.distributed.parallel_loader as pl
# import torch_xla.distributed.xla_multiprocessing as xmp
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.policies import ActorCriticPolicy
from stable_baselines3.common.env_util import make_vec_env
from torch.nn.utils.rnn import pad_sequence
from torch.distributions import Categorical
from understat import Understat
import asyncio
import aiohttp
import ssl
import certifi
import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.feature_selection import RFECV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier
from sklearn.model_selection import learning_curve
from xgboost import plot_importance
import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score, precision_recall_curve
import time
from sklearn.model_selection import cross_val_predict
import statistics
import pickle
from joblib import dump, load
from torch.utils.data import DataLoader, TensorDataset
from transformers import BertTokenizer, BertForSequenceClassification
from transformers import BertModel
from transformers import AdamW
from torch.nn import TransformerEncoder, TransformerEncoderLayer, Dropout
from torch.optim.lr_scheduler import OneCycleLR
import copy
from torch.optim import Adam
import torch.nn.functional as F
from google.colab import files





class BettingEnv(gym.Env):
    metadata = {'render.modes': ['human']}

    def __init__(self, feature_data, time_data, attention_data):
        super(BettingEnv, self).__init__()
        self.transformer_model = transformer_model
        assert len(feature_data) == len(time_data) == len(attention_data), "Data vectors must be of equal length."

        self.feature_data = feature_data
        self.time_data = time_data
        self.attention_data = attention_data
        self.n_games = len(feature_data)
        self.current_game = 0

        # Example: Adjust these based on the actual sizes of your vectors
        feature_size = len(feature_data[0])
        time_size = len(time_data[0])
        attention_size = len(attention_data[0])

        # Define action and observation space
        self.action_space = spaces.Discrete(5)  # Actions: 0 - do nothing, 1 - bet on win, etc.

        # Observation space combines feature, time, and attention vectors
        total_observation_size = feature_size + time_size + attention_size
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(total_observation_size,), dtype=np.float32)

    def step(self, action):
        reward = self.calculate_reward(action, self.current_game)
        self.current_game += 1
        done = self.current_game >= self.n_games
        next_state = self.get_next_state(self.current_game) if not done else np.zeros(self.observation_space.shape)
        return next_state, reward, done, {}

    def reset(self):
        self.current_game = 0
        return self.get_next_state(self.current_game)

    def render(self, mode='human'):
        # Optional: Implement visualization
        pass

    def calculate_reward(self, action, game_idx):
        # Placeholder: Implement your reward calculation logic
        if action == 0:

            return 0
        elif action == 1:
            return 1
        return 0

    def get_next_state(self, game_idx):
        # Prepare data for Transformer
        feature_vector = torch.tensor(self.feature_data[game_idx], dtype=torch.float).unsqueeze(0)  # Add batch dimension
        time_vector = torch.tensor(self.time_data[game_idx], dtype=torch.float).unsqueeze(0)
        attention_vector = torch.tensor(self.attention_data[game_idx], dtype=torch.float).unsqueeze(0)

        # Process through Transformer (assuming it's already trained and in evaluation mode)
        with torch.no_grad():
            transformer_output = self.transformer_model(feature_vector, attention_vector).squeeze(0)  # Remove batch dimension

        # Incorporate Transformer output into the state
        next_state = np.concatenate((feature_vector.numpy(), time_vector.numpy(), transformer_output.numpy()))
        return next_state


# class NumericalTransformerModel(nn.Module):
#     def __init__(self, input_dim, num_heads, num_encoder_layers, num_classes):
#         super(NumericalTransformerModel, self).__init__()
#         self.input_dim = input_dim
#         encoder_layer = TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=512)
#         self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)
#         self.fc_out = nn.Linear(input_dim, num_classes)

#     def forward(self, src, src_key_padding_mask=None):
#         # Assuming src is of shape [seq_len, batch_size, input_dim]
#         output = self.transformer_encoder(src, src_key_padding_mask=src_key_padding_mask)
#         output = output.mean(dim=0)  # Average over the sequence dimension
#         return self.fc_out(output)

class NumericalTransformerModel(nn.Module):
    def __init__(self, input_dim, num_heads, num_encoder_layers, num_classes, dropout_rate=0):
        super(NumericalTransformerModel, self).__init__()
        self.input_dim = input_dim
        # Initialize an encoder layer with dropout
        encoder_layer = TransformerEncoderLayer(d_model=input_dim, nhead=num_heads,
                                                dim_feedforward=512, dropout=dropout_rate)
        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)
        self.dropout = nn.Dropout(dropout_rate)  # Dropout layer before the final output
        self.fc_out = nn.Linear(input_dim, num_classes)

    def forward(self, src, src_key_padding_mask=None):
        # Assuming src is of shape [seq_len, batch_size, input_dim]
        output = self.transformer_encoder(src, src_key_padding_mask=src_key_padding_mask)
        output = output.mean(dim=0)  # Average over the sequence dimension
        output = self.dropout(output)  # Apply dropout
        return self.fc_out(output)

def positional_encoding(seq_len, d_model, device=torch.device('cpu')):
    """
    Generates a matrix of positional encodings.

    Args:
    - seq_len (int): Length of the sequence or position indices.
    - d_model (int): The dimension of the embeddings/token representations.
    - device (torch.device): The device to create the positional encodings on.

    Returns:
    - pos_enc (torch.tensor): The positional encoding matrix.
    """
    pos_enc = np.array([
        [pos / np.power(10000, 2 * (j // 2) / d_model) for j in range(d_model)]
        if pos != 0 else np.zeros(d_model)
        for pos in range(seq_len)
    ])
    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2])  # dim 2i
    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2])  # dim 2i+1
    return torch.tensor(pos_enc, dtype=torch.float32).to(device)

def add_positional_encoding(embeddings, seq_len, d_model, device=torch.device('cpu')):
    """
    Adds positional encodings to embeddings.

    Args:
    - embeddings (torch.tensor): The input embeddings tensor.
    - seq_len (int): Length of the sequence or position indices.
    - d_model (int): The dimension of the embeddings/token representations.
    - device (torch.device): The device the embeddings are on.

    Returns:
    - embeddings_with_pos (torch.tensor): Embeddings tensor with positional encodings added.
    """
    pos_enc = positional_encoding(seq_len, d_model, device)
    embeddings_with_pos = embeddings + pos_enc
    return embeddings_with_pos

async def main():
  if torch.cuda.is_available():
    device = torch.device("cuda")
    print(f"GPU available: {torch.cuda.get_device_name(0)}")
  else:
      device = torch.device("cpu")
      print("GPU not available, using CPU instead.")
  # with open('reinforcement_vector_list.pickle', 'rb') as file:
  #     full_vector_list = pickle.load(file)

  # with open('reinforcement_time_vector_list.pickle', 'rb') as file:
  #     full_time_vector_list = pickle.load(file)

  with open('reinforcement_attention_mechanism_vector_list.pickle', 'rb') as file:
        attention_mechanism_vector_list = pickle.load(file)
  # # print(f'attention_mechanism_vector_list: {attention_mechanism_vector_list}')
  with open('reinforcement_target_list.pickle', 'rb') as file:
        target_list = pickle.load(file)
  # # # print(f'target_list: {target_list}')
  # full_vector_list = np.array(full_vector_list)
  # time_vectors = np.array(full_time_vector_list)
  # year_features = time_vectors[:, 0].reshape(-1, 1)



  # scaler = StandardScaler()
  # full_vector_list = scaler.fit_transform(full_vector_list)
  # # dump(scaler, 'full_vector_list_scaler.joblib')
  # # files.download('full_vector_list_scaler.joblib')

  # # # Step 1: Identify valid years (e.g., 2010-2030) and placeholder years
  # # valid_years_mask = (time_vectors[:, 0] >= 2010) & (time_vectors[:, 0] <= 2030)
  # # placeholder_years_mask = ~valid_years_mask

  # # # Step 2: Replace placeholder years with NaN to calculate the mean of valid years only
  # # time_vectors[placeholder_years_mask, 0] = np.nan
  # # mean_valid_year = np.nanmean(time_vectors[:, 0])

  # # # Step 3: Replace NaNs (previously placeholder years) with the mean of valid years
  # # time_vectors[np.isnan(time_vectors[:, 0]), 0] = mean_valid_year

  # standardized_time_vectors = []
  # for time_vector in full_time_vector_list:
  #     # Assuming time_vectors is your existing list of time vectors
  #     # time_vectors_adjusted = [tv[:-1] for tv in time_vectors]

  #     # Extract year from each sample's time vector
  #     years = np.array([tv[0] for tv in time_vector]).reshape(-1, 1)

  #     # Standardize years within this specific sample
  #     standardized_years = scaler.fit_transform(years).flatten()
  #     # dump(scaler, 'standardized_years_scaler.joblib')
  #     # files.download('standardized_years_scaler.joblib')

  #     # Replace the year in the original time vector
  #     for idx, _ in enumerate(time_vector):
  #         time_vector[idx][0] = standardized_years[idx]

  #     standardized_time_vectors.append(time_vector)


  # game_data_2d_list = []
  # for i in range(len(full_vector_list)):
  #     feature_list = full_vector_list[i]
  #     time_list = standardized_time_vectors[i]

  #     feature_array = np.array(feature_list)
  #     feature_array_expanded = np.expand_dims(feature_array, axis=-1)
  #     time_array = np.array(time_list)

  #     # game_data_2d = np.stack((feature_array, time_array), axis=-1)
  #     game_data_2d = np.concatenate((feature_array_expanded, time_array), axis=-1)
  #     game_data_2d_list.append(game_data_2d)

  # with open('reinforcement_game_data_2d_list.pickle', 'wb') as file:
  #     pickle.dump(game_data_2d_list, file)
  with open('reinforcement_game_data_2d_list.pickle', 'rb') as file:
        game_data_2d_list = pickle.load(file)

  seq_len = max(len(item) for item in game_data_2d_list)  # Find the maximum sequence length
  # print(game_data_2d_list[0].shape[1])
  d_model = game_data_2d_list[0].shape[1]  # Assuming all sequences have the same feature dimension
  # d_model = game_data_2d_list[0].shape[1]  # Assuming all sequences have the same feature dimension

  # Generate positional encoding matrix
  pos_enc_matrix = positional_encoding(seq_len, d_model)
  # pos_enc_matrix = positional_encoding(seq_len, game_data_2d_list[0].shape[1])

  # Add positional encoding to each sequence
  game_data_2d_list_with_pos = []
  for game_data_2d in game_data_2d_list:
      seq_length = game_data_2d.shape[0]
      # Add only the relevant part of the positional encoding
      pos_enc_for_this_seq = pos_enc_matrix[:seq_length, :]
      game_data_2d_with_pos = game_data_2d + pos_enc_for_this_seq.numpy()
      game_data_2d_list_with_pos.append(game_data_2d_with_pos)

  game_data_2d_np_array = np.array(game_data_2d_list_with_pos)
  # Convert lists to PyTorch tensors
  game_data_2d_tensor = torch.tensor(game_data_2d_np_array, dtype=torch.float)
  # game_data_2d_tensor = torch.tensor(game_data_2d_list_with_pos, dtype=torch.float)
  attention_mask_tensor = torch.tensor(attention_mechanism_vector_list, dtype=torch.bool)
  target_tensor = torch.tensor(target_list, dtype=torch.long)

  # Split the dataset into training and validation
  inputs_train, inputs_val, masks_train, masks_val, labels_train, labels_val = train_test_split(
      game_data_2d_tensor, attention_mask_tensor, target_tensor, test_size=0.1, random_state=42
  )

  # Create TensorDatasets
  train_dataset = TensorDataset(inputs_train, masks_train, labels_train)
  val_dataset = TensorDataset(inputs_val, masks_val, labels_val)

  # Create DataLoaders
  batch_size = 32  # You can adjust the batch size
  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)


  # Model Initialization
  input_dim = game_data_2d_tensor.shape[2]  # Assuming [batch_size, seq_len, features]
  num_heads = 7  # Example value, adjust as necessary
  num_encoder_layers = 1   # Example value
  num_classes = 3  # Adjust based on your specific task
  model = NumericalTransformerModel(input_dim, num_heads, num_encoder_layers, num_classes)
  # model = ModifiedTransformerEncoderLayer(d_model, num_heads, dim_feedforward=2048, dropout=0.1)

  num_epochs = 100
  # num_epochs = 200
  model = model.to(device)
  # Optimizer and Loss Function
  optimizer = torch.optim.Adam(model.parameters(), lr=.001)
  # scheduler = OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=num_epochs)
  loss_fn = nn.CrossEntropyLoss()
  best_val_loss = 2
  best_model_state = copy.deepcopy(model.state_dict())
  patience = 20  # Number of epochs to wait after last time validation loss improved.
  patience_counter = 0


  for epoch in range(num_epochs):
    model.train()  # Set model to training mode
    total_train_loss = 0
    for batch in train_loader:
        inputs, masks, labels = batch
        inputs, masks, labels = inputs.to(device), masks.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs.permute(1, 0, 2), src_key_padding_mask=masks)
        # outputs = model(inputs, src_key_padding_mask=masks)
        loss = loss_fn(outputs, labels)
        loss.backward()
        optimizer.step()

        total_train_loss += loss.item()

    avg_train_loss = total_train_loss / len(train_loader)

    # Validation phase
    model.eval()  # Set model to evaluation mode
    total_val_loss = 0
    with torch.no_grad():
        for batch in val_loader:
            inputs, masks, labels = batch
            inputs, masks, labels = inputs.to(device), masks.to(device), labels.to(device)

            outputs = model(inputs.permute(1, 0, 2), src_key_padding_mask=masks)
            loss = loss_fn(outputs, labels)

            total_val_loss += loss.item()

    avg_val_loss = total_val_loss / len(val_loader)

    print(f"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}")
  # torch.save(model.state_dict(), 'transformer_model.pth')
      # Check if current epoch's validation loss is the best we've seen so far
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        best_model_state = copy.deepcopy(model.state_dict())
        patience_counter = 0  # Reset counter
        print("Validation loss decreased, saving model...")
    else:
        patience_counter += 1

    # Early stopping check
    if patience_counter >= patience:
        print(f"Stopping early at epoch {epoch+1}")
        break
    # if epoch % 100 == 0:
    #   # Save the best model
    #   print('SAVING MODEL')
    #   torch.save(model.state_dict(), 'best_model_gpu.pth')

  # Load the best model state
  model.load_state_dict(best_model_state)

  # Save the best model
  print('SAVING MODEL')
  model_save_path = 'best_model_gpu3.pth'
  torch.save(model.state_dict(), model_save_path)
  # files.download(model_save_path)
if __name__ == '__main__':
    # asyncio.run(main())
    await main()


    # (.001,1,.9921),()

from sklearn.inspection import permutation_importance
from sklearn.metrics import accuracy_score
with open('reinforcement_test_vector_list.pickle', 'rb') as file:
    test_vector_list = pickle.load(file)

with open('reinforcement_test_time_vector_list.pickle', 'rb') as file:
    test_time_vector_list = pickle.load(file)

with open('reinforcement_test_attention_mechanism_vector_list.pickle', 'rb') as file:
    test_attention_mechanism_vector_list = pickle.load(file)

with open('reinforcement_test_target_list.pickle', 'rb') as file:
    test_target_list = pickle.load(file)

with open('reinforcement_game_info_list.pickle', 'rb') as file:
    game_info_list = pickle.load(file)

input_dim = 7  # Assuming [batch_size, seq_len, features]
num_heads = 7  # Example value, adjust as necessary
num_encoder_layers = 3   # Example value
num_classes = 3  # Adjust based on your specific task
# Step 1: Define the model
model = NumericalTransformerModel(input_dim, num_heads, num_encoder_layers, num_classes)  # Replace MyModel with your model's class name

# Step 2: Load the saved model 'best_model_gpu.pth'
# model_load_path = '/home/user/Desktop/GitHub Projects/BettingData/best_model_gpu.pth'
model_load_path = 'best_model_gpu3.pth'
model.load_state_dict(torch.load(model_load_path))
model.eval()

test_vector_list = np.array(test_vector_list)
test_time_vector_list = np.array(test_time_vector_list)
year_features = test_time_vector_list[:, 0].reshape(-1, 1)



scaler = load('full_vector_list_scaler.joblib')
test_vector_list = scaler.transform(test_vector_list)
# scaler = StandardScaler()
# test_vector_list = scaler.fit_transform(test_vector_list)


standardized_time_vectors = []
for time_vector in test_time_vector_list:

    # Extract year from each sample's time vector
    years = np.array([tv[0] for tv in time_vector]).reshape(-1, 1)

    # Standardize years within this specific sample
    # scaler = load('standardized_years_scaler.joblib')
    # standardized_years = scaler.transform(years).flatten()
    standardized_years = scaler.fit_transform(years).flatten()

    # Replace the year in the original time vector
    for idx, _ in enumerate(time_vector):
        time_vector[idx][0] = standardized_years[idx]

    standardized_time_vectors.append(time_vector)


test_game_data_2d_list = []
for i in range(len(test_vector_list)):
    feature_list = test_vector_list[i]
    time_list = standardized_time_vectors[i]

    feature_array = np.array(feature_list)
    feature_array_expanded = np.expand_dims(feature_array, axis=-1)
    time_array = np.array(time_list)

    # game_data_2d = np.stack((feature_array, time_array), axis=-1)
    test_game_data_2d = np.concatenate((feature_array_expanded, time_array), axis=-1)
    test_game_data_2d_list.append(test_game_data_2d)

with open('reinforcement_test_game_data_2d_list.pickle', 'wb') as file:
    pickle.dump(test_game_data_2d_list, file)
with open('reinforcement_test_game_data_2d_list.pickle', 'rb') as file:
      test_game_data_2d_list = pickle.load(file)

seq_len = max(len(item) for item in test_game_data_2d_list)  # Find the maximum sequence length
# print(game_data_2d_list[0].shape[1])
d_model = test_game_data_2d_list[0].shape[1]  # Assuming all sequences have the same feature dimension
# d_model = game_data_2d_list[0].shape[1]  # Assuming all sequences have the same feature dimension

# Generate positional encoding matrix
pos_enc_matrix = positional_encoding(seq_len, d_model)
# pos_enc_matrix = positional_encoding(seq_len, game_data_2d_list[0].shape[1])

# Add positional encoding to each sequence
test_game_data_2d_list_with_pos = []
for game_data_2d in test_game_data_2d_list:
    seq_length = game_data_2d.shape[0]
    # Add only the relevant part of the positional encoding
    pos_enc_for_this_seq = pos_enc_matrix[:seq_length, :]
    game_data_2d_with_pos = game_data_2d + pos_enc_for_this_seq.numpy()
    test_game_data_2d_list_with_pos.append(game_data_2d_with_pos)

game_data_2d_np_array = np.array(test_game_data_2d_list_with_pos)
# Convert lists to PyTorch tensors
game_data_2d_tensor = torch.tensor(game_data_2d_np_array, dtype=torch.float)
# game_data_2d_tensor = torch.tensor(game_data_2d_list_with_pos, dtype=torch.float)
attention_mask_tensor = torch.tensor(test_attention_mechanism_vector_list, dtype=torch.bool)
target_tensor = torch.tensor(test_target_list, dtype=torch.long)

# # Step 3: Prepare your data
# # Assuming you have a Dataset class for your data
test_dataset = TensorDataset(game_data_2d_tensor, attention_mask_tensor, target_tensor)  # Adjust as necessary
# Prepare DataLoader for single-item batches
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)


home_correct = 0
home_incorrect = 0
away_correct = 0
away_incorrect = 0
draw_correct = 0
draw_incorrect = 0
home_draw_correct = 0
home_draw_incorrect = 0
away_draw_correct = 0
away_draw_incorrect = 0
correct = 0
total = 0

# with torch.no_grad():
#     for i, (inputs, masks, labels) in enumerate(test_loader):
#         output = model(inputs.squeeze(0), masks.squeeze(0))  # Adjust dimensions if necessary
#         probabilities = F.softmax(output, dim=1)
#         predicted_class = probabilities.argmax(dim=1)
#         game_info = game_info_list[i]  # Ensure this is correctly indexed
with torch.no_grad():
  for i, (inputs, masks, labels) in enumerate(test_loader):
      # Ensure inputs and masks maintain their batch dimension
      inputs = inputs.squeeze(0)  # Adjust dimensions if necessary
      masks = masks.squeeze(0)  # Adjust dimensions if necessary
      output = model(inputs, masks)

      # Ensure output maintains its batch dimension
      if output.dim() == 1:
          output = output.unsqueeze(0)  # Adds a batch dimension

      probabilities = F.softmax(output, dim=1)
      predicted_class = probabilities.argmax(dim=1)
      game_info = game_info_list[i]  # Ensure this is correctly indexed

      print(f"Game info: {game_info}")
      print(f"Predicted class: {predicted_class.item()}, Right class: {labels.item()}, Probabilities: {probabilities.squeeze().tolist()}")

      if predicted_class.item() == 0:
        if labels.item() == 0:
          home_correct += 1
          home_draw_correct += 1
          correct += 1
        elif labels.item() == 1:
          home_incorrect += 1
          home_draw_correct += 1
        elif labels.item() == 2:
          home_incorrect += 1
          home_draw_incorrect += 1
      elif predicted_class.item() == 1:
        if labels.item() == 0:
          draw_incorrect += 1
        elif labels.item() == 1:
          draw_correct += 1
          correct += 1
        elif labels.item() == 2:
          draw_incorrect += 1
      elif predicted_class.item() == 2:
        if labels.item() == 0:
          away_incorrect += 1
          away_draw_incorrect += 1
        elif labels.item() == 1:
          away_incorrect += 1
          away_draw_correct += 1
        elif labels.item() == 2:
          away_draw_correct += 1
          away_correct += 1
          correct += 1
      total += 1

print(f"Home Accuracy: {100 * home_correct / (home_correct + home_incorrect)}%")
print(f"Home/Draw Accuracy: {100 * home_draw_correct / (home_draw_correct + home_draw_incorrect)}%")
print(f"Away Accuracy: {100 * away_correct / (away_correct + away_incorrect)}%")
print(f"Away/Draw Accuracy: {100 * away_draw_correct / (away_draw_correct + away_draw_incorrect)}%")
if draw_correct + draw_incorrect == 0:
  print(f"Draw Accuracy: 0%")
else:
  print(f"Draw Accuracy: {100 * draw_correct / (draw_correct + draw_incorrect)}%")
print(f"Total Accuracy: {100 * correct / total}%")

# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # Adjust batch_size as necessary

# # Step 4: Evaluate
# model.eval()  # Set the model to evaluation mode
# correct = 0
# total = 0
# counter = 0
# with torch.no_grad():
#   for batch in test_loader:
#       counter += 1
#       inputs, masks, labels = batch
#       output = model(inputs.permute(1, 0, 2), src_key_padding_mask=masks)
#       probabilities = F.softmax(output, dim=1)
#       predicted_class = output.argmax(dim=1)
#       (game, game_result) = game_info_list[counter]
#       print(f"{game[0]} vs {game[1]} at {game_result[game][1]}:")
#       print(f'Probability was {probabilities}. You predicted {predicted_class.item()} to win')
#       print(f'Score: {game_result[game][3]} - {game_result[game][4]}')
#       if predicted_class.item() == labels:
#           correct += 1
#       total += 1


# print(f'Accuracy of the model on the games: {100 * correct / total}%')

def table_at_game(league,season):
    file_path = f'table_at_game_{league}_{season}.json'
    with open(file_path, 'r') as json_file:
        # Load the JSON data from the file
        data = json.load(json_file)
    for key in data:
        data[key] = {tuple(team.split('_')): value for team, value in data[key].items()}
    return data

def table_dict(league,season):
    file_path = f'table_dictionary_{league}_{season}.json'
    with open(file_path, 'r') as json_file:
        # Load the JSON data from the file
        data = json.load(json_file)
    return data
def results_list(league,season):
    file_path = f'results_{league}_{season}.json'
    with open(file_path, 'r') as json_file:
        # Load the JSON data from the file
        data = json.load(json_file)
    return data
def cyclical_encode(date):
    date_obj = datetime.strptime(date, "%Y-%m-%d")
    month = date_obj.month
    day = date_obj.day
    year = date_obj.year
    month_sin = np.sin(2 * np.pi * month / 12)
    month_cos = np.cos(2 * np.pi * month / 12)
    day_sin = np.sin(2 * np.pi * day / 31)
    day_cos = np.cos(2 * np.pi * day / 31)
    return [year, month_sin, month_cos, day_sin, day_cos, 0]
def form_before_game(form_list,date):
    cutoff_date = datetime.strptime(date, '%Y-%m-%d')
    games_before_cutoff = [game[0] for game in form_list]
    date_of_game_before_cutoff =[cyclical_encode(game[1]) for game in form_list]
    attention = []
    for game in form_list:
        if datetime.strptime(game[1], '%Y-%m-%d') < cutoff_date:
            attention.append(1)
        else:
            attention.append(0)
    if games_before_cutoff == []:
        games_before_cutoff = [3]
    for _ in range(len(games_before_cutoff),40):
        games_before_cutoff.append(-1)
        date_of_game_before_cutoff.append(cyclical_encode('1099-07-01'))
        attention.append(0)
    return games_before_cutoff,date_of_game_before_cutoff,attention

def historical_data(league, season,starting_season):
    historical_data = {}
    xg_historical_data = {}
    historical_data_dates = {}
    xg_historical_data_dates = {}
    historical_data_attention = {}
    xg_historical_data_attention = {}
    w_1 = []
    w_2 = []
    w_3 = []
    w_4 = []
    w_5 = []
    w_6 = []
    for i in range(2014,season):
        results = results_list(league,i)

        for match in results:
            home_team = match['h']['title']
            away_team = match['a']['title']
            home_goals = match['goals']['h']
            away_goals = match['goals']['a']
            xg_home = float(match['xG']['h'])
            xg_away = float(match['xG']['a'])
            datetime_str = match['datetime']
            datetime_obj = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')
            one_day_before = datetime_obj - timedelta(days=1)
            date = one_day_before.strftime('%Y-%m-%d')

            xg_result = 'draw' if round(xg_home - xg_away) == 0 else 'home_win' if round(xg_home - xg_away) > 0 else 'away_win'

            real_result = 'draw' if home_goals == away_goals else 'home_win' if home_goals > away_goals else 'away_win'


            if (home_team,away_team) not in xg_historical_data:
                xg_historical_data[(home_team,away_team)] = [3] * (i - 2014)
                w_1.extend([3] * (i - 2014))
                xg_historical_data_dates[(home_team,away_team)] = [cyclical_encode('3003-07-01')]*(i - 2014)
                w_2.extend([cyclical_encode('3003-07-01')]*(i - 2014))
                xg_historical_data_attention[(home_team,away_team)] = [1] * (i - 2014)
                w_3.extend([1] * (i - 2014))
            if xg_result == 'draw':
                xg_historical_data[(home_team,away_team)].append(1)
                # w_1.append(1)
            elif xg_result == 'home_win':
                xg_historical_data[(home_team,away_team)].append(0)
                # w_1.append(1)
            else:
                xg_historical_data[(home_team,away_team)].append(2)
                # w_1.append(1)
            xg_historical_data_dates[(home_team,away_team)].append(cyclical_encode(date))
            # w_2.append(1)
            xg_historical_data_attention[(home_team,away_team)].append(1)
            # w_3.append(1)


            if (home_team,away_team) not in historical_data:
                historical_data[(home_team,away_team)] = [3] * (i - 2014)
                w_4.extend([3] * (i - 2014))
                historical_data_dates[(home_team,away_team)] = [cyclical_encode('3003-07-01')]*(i - 2014)
                w_5.extend([cyclical_encode(f'{i}-07-01')]*(i - 2014))
                historical_data_attention[(home_team,away_team)] = [1] * (i - 2014)
                w_6.extend([1] * (i - 2014))
            if real_result == 'draw':
                historical_data[(home_team,away_team)].append(1)
                # w_4.append(1)
            elif real_result == 'home_win':
                historical_data[(home_team,away_team)].append(0)
                # w_4.append(1)
            else:
                historical_data[(home_team,away_team)].append(2)
                # w_4.append(1)
            historical_data_dates[(home_team,away_team)].append(cyclical_encode(date))
            # w_5.append(cyclical_encode(date))
            historical_data_attention[(home_team,away_team)].append(1)
            # w_6.append(1)

        for game in historical_data:
            if len(historical_data[game]) != (i - 2014 + 1):
                historical_data[game].append(3)
                # w_4.append(1)
                historical_data_dates[game].append(cyclical_encode(f'{i}-07-01'))
                # w_5.append(cyclical_encode('1099-07-01'))
                historical_data_attention[game].append(1)
                # w_6.append(1)

        for game in xg_historical_data:
            if len(xg_historical_data[game]) != (i - 2014 + 1):
                xg_historical_data[game].append(3)
                # w_1.append(1)
                xg_historical_data_dates[game].append(cyclical_encode(f'{i}-07-01'))
                # w_2.append(1)
                xg_historical_data_attention[game].append(1)
                # w_3.append(1)

    for i in range(starting_season, season, -1):
        for game in historical_data:
            historical_data[game].append(-2)
            # w_4.append(1)
            xg_historical_data[game].append(-2)
            # w_1.append(1)
            historical_data_dates[game].append(cyclical_encode(f'{i}-07-01'))
            # w_5.append((cyclical_encode('3002-07-01')))
            xg_historical_data_dates[game].append(cyclical_encode(f'{i}-07-01'))
            # w_2.append(1)
            historical_data_attention[game].append(0)
            # w_6.append(1)
            xg_historical_data_attention[game].append(0)
            # w_3.append(1)
    # print(historical_data['Crystal Palace','Arsenal'])
    # for game in historical_data:
    #     if len(historical_data[game]) != 8:
    #         print(game)

    # print(len(w_1))
    # print(len(w_2))
    # print(len(w_3))
    # print(len(w_4))
    # print(len(w_5))
    # print(len(w_6))

    return historical_data,xg_historical_data,historical_data_dates,xg_historical_data_dates,historical_data_attention,xg_historical_data_attention

def x_years_before_table(table_dictionary,season_year,league):
    full_table_dictionary = {}
    home_table_dictionary = {}
    away_table_dictionary = {}

    season = table_dictionary[f'full_league_table_{league}_{season_year}']
    counter = 0
    teams = [team[0] for team in season if team[0] != 'Team']
    for team in teams:
        counter += 1
        full_table_dictionary[f'{team}'] = counter

    season = table_dictionary[f'home_league_table_{league}_{season_year}']
    counter = 0
    teams = [team[0] for team in season if team[0] != 'Team']
    for team in teams:
        counter += 1
        home_table_dictionary[f'{team}'] = counter

    season = table_dictionary[f'away_league_table_{league}_{season_year}']
    counter = 0
    teams = [team[0] for team in season if team[0] != 'Team']
    for team in teams:
        counter += 1
        away_table_dictionary[f'{team}'] = counter
    return full_table_dictionary,home_table_dictionary,away_table_dictionary

def recent_form(league, season):
    recent_form_dictionary = {}
    recent_home_form_dictionary = {}
    recent_away_form_dictionary = {}
    xg_recent_form_dictionary = {}
    xg_recent_home_form_dictionary = {}
    xg_recent_away_form_dictionary = {}

    results = results_list(league,season)

    for match in results:
        home_team = match['h']['title']
        away_team = match['a']['title']
        home_goals = match['goals']['h']
        away_goals = match['goals']['a']
        xg_home = float(match['xG']['h'])
        xg_away = float(match['xG']['a'])
        datetime_str = match['datetime']
        datetime_obj = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')
        one_day_before = datetime_obj - timedelta(days=1)
        date = one_day_before.strftime('%Y-%m-%d')

        xg_result = 'draw' if round(xg_home - xg_away) == 0 else 'home_win' if round(xg_home - xg_away) > 0 else 'away_win'

        real_result = 'draw' if home_goals == away_goals else 'home_win' if home_goals > away_goals else 'away_win'

        if home_team not in recent_form_dictionary:
            recent_form_dictionary[home_team] = []
        if away_team not in recent_form_dictionary:
            recent_form_dictionary[away_team] = []
        if home_team not in recent_home_form_dictionary:
            recent_home_form_dictionary[home_team] = []
        if away_team not in recent_away_form_dictionary:
            recent_away_form_dictionary[away_team] = []
        if home_team not in xg_recent_form_dictionary:
            xg_recent_form_dictionary[home_team] = []
        if away_team not in xg_recent_form_dictionary:
            xg_recent_form_dictionary[away_team] = []
        if home_team not in xg_recent_home_form_dictionary:
            xg_recent_home_form_dictionary[home_team] = []
        if away_team not in xg_recent_away_form_dictionary:
            xg_recent_away_form_dictionary[away_team] = []

        if real_result == 'home_win':
            recent_form_dictionary[home_team].append((0,date))
            recent_form_dictionary[away_team].append((2,date))
            recent_home_form_dictionary[home_team].append((0,date))
            recent_away_form_dictionary[away_team].append((2,date))
        if real_result == 'away_win':
            recent_form_dictionary[home_team].append((2,date))
            recent_form_dictionary[away_team].append((0,date))
            recent_home_form_dictionary[home_team].append((2,date))
            recent_away_form_dictionary[away_team].append((0,date))
        if real_result == 'draw':
            recent_form_dictionary[home_team].append((1,date))
            recent_form_dictionary[away_team].append((1,date))
            recent_home_form_dictionary[home_team].append((1,date))
            recent_away_form_dictionary[away_team].append((1,date))


        if xg_result == 'home_win':
            xg_recent_form_dictionary[home_team].append((0,date))
            xg_recent_form_dictionary[away_team].append((2,date))
            xg_recent_home_form_dictionary[home_team].append((0,date))
            xg_recent_away_form_dictionary[away_team].append((2,date))
        if xg_result == 'away_win':
            xg_recent_form_dictionary[home_team].append((2,date))
            xg_recent_form_dictionary[away_team].append((0,date))
            xg_recent_home_form_dictionary[home_team].append((2,date))
            xg_recent_away_form_dictionary[away_team].append((0,date))
        if xg_result == 'draw':
            xg_recent_form_dictionary[home_team].append((1,date))
            xg_recent_form_dictionary[away_team].append((1,date))
            xg_recent_home_form_dictionary[home_team].append((1,date))
            xg_recent_away_form_dictionary[away_team].append((1,date))

    return recent_form_dictionary,recent_home_form_dictionary,recent_away_form_dictionary,xg_recent_form_dictionary,xg_recent_home_form_dictionary,xg_recent_away_form_dictionary
def predict_vector(future_game,league,season,home_full_table_position,away_full_table_position,home_table_position,away_table_position,date,odds):
    game_results = {}
    game_results[future_game] = (2,date,'none',-1,-1)

    real_history, xg_history, real_history_dates, xg_history_dates,historical_data_attention, xg_historical_data_attention = historical_data(league, season, season)
    full_recent_form,home_recent_form,away_recent_form,xg_full_recent_form,xg_home_recent_form,xg_away_recent_form = recent_form(league, season)
    vector_list = []
    time_vector_list = []
    attention_mechanism_vector_list = []

    for game in game_results:
        vector = []
        time_vector = []
        attention_mechanism_vector = []
        #ADD YEAR
        vector.append(season)
        time_vector.append([season,0,0,0,0,1])
        attention_mechanism_vector.append(1)

        #ADD ODDS

        vector.append(odds)
        time_vector.append([season,0,0,0,0,1])
        attention_mechanism_vector.append(1)

        #ADD CURRENT TABLE POSITIONS
        vector.append(home_full_table_position)
        vector.append(away_full_table_position)
        time_vector.extend([[season,0,0,0,0,1],[season,0,0,0,0,1]])
        attention_mechanism_vector.extend([1,1])

        vector.append(home_table_position)
        vector.append(away_table_position)
        time_vector.extend([[season,0,0,0,0,1],[season,0,0,0,0,1]])
        attention_mechanism_vector.extend([1,1])

        #ADD HISTORICAL TABLE POSITIONS
        for i in range(season, season, -1):
            vector.extend([-1]*4)
            time_vector.extend([[i,0,0,0,0,1]]*4)
            attention_mechanism_vector.extend([0]*4)

        for i in range(1,season - 2014 + 1):
            if game[0] in x_years_before_table(table_dict(league,season-i),season-i,league)[0]:
                if game[1] in x_years_before_table(table_dict(league,season-i),season-i,league)[0]:
                    vector.append(x_years_before_table(table_dict(league,season-i),season-i,league)[0][game[0]])
                    vector.append(x_years_before_table(table_dict(league,season-i),season-i,league)[0][game[1]])
                    time_vector.extend([[season-i,0,0,0,0,1],[season-i,0,0,0,0,1]])
                    attention_mechanism_vector.extend([1,1])
                else:
                    vector.append(x_years_before_table(table_dict(league,season-i),season-i,league)[0][game[0]])
                    vector.append(21)
                    time_vector.extend([[season-i,0,0,0,0,1],[season-i,0,0,0,0,1]])
                    attention_mechanism_vector.extend([1,1])
            else:
                if game[1] in x_years_before_table(table_dict(league,season-i),season-i,league)[0]:
                    vector.append(21)
                    vector.append(x_years_before_table(table_dict(league,season-i),season-i,league)[0][game[1]])
                    time_vector.extend([[season-i,0,0,0,0,1],[season-i,0,0,0,0,1]])
                    attention_mechanism_vector.extend([1,1])
                else:
                    vector.append(21)
                    vector.append(21)
                    time_vector.extend([[season-i,0,0,0,0,1],[season-i,0,0,0,0,1]])
                    attention_mechanism_vector.extend([1,1])
            if game[0] in x_years_before_table(table_dict(league,season-i),season-i,league)[1]:
                if game[1] in x_years_before_table(table_dict(league,season-i),season-i,league)[2]:
                    vector.append(x_years_before_table(table_dict(league,season-i),season-i,league)[1][game[0]])
                    vector.append(x_years_before_table(table_dict(league,season-i),season-i,league)[2][game[1]])
                    time_vector.extend([[season-i,0,0,0,0,1],[season-i,0,0,0,0,1]])
                    attention_mechanism_vector.extend([1,1])
                else:
                    vector.append(x_years_before_table(table_dict(league,season-i),season-i,league)[1][game[0]])
                    vector.append(21)
                    time_vector.extend([[season-i,0,0,0,0,1],[season-i,0,0,0,0,1]])
                    attention_mechanism_vector.extend([1,1])
            else:
                if game[1] in x_years_before_table(table_dict(league,season-i),season-i,league)[2]:
                    vector.append(21)
                    vector.append(x_years_before_table(table_dict(league,season-i),season-i,league)[2][game[1]])
                    time_vector.extend([[season-i,0,0,0,0,1],[season-i,0,0,0,0,1]])
                    attention_mechanism_vector.extend([1,1])
                else:
                    vector.append(21)
                    vector.append(21)
                    time_vector.extend([[season-i,0,0,0,0,1],[season-i,0,0,0,0,1]])
                    attention_mechanism_vector.extend([1,1])
        #ADD HISTORICAL GAME RESULTS
        if game in real_history:
            vector.extend(real_history[game])
            time_vector.extend(real_history_dates[game])
            attention_mechanism_vector.extend(historical_data_attention[game])
        else:
            vector.extend([3]*(season-2014))
            time_vector.extend([cyclical_encode('3002-07-01')]*(season-2014))
            attention_mechanism_vector.extend([1]*(season-2014))
        print(real_history[game])
        print(real_history_dates[game])
        print(historical_data_attention[game])

        if game in xg_history:
            vector.extend(xg_history[game])
            time_vector.extend(xg_history_dates[game])
            attention_mechanism_vector.extend(xg_historical_data_attention[game])
        else:
            vector.extend([3]*(season-2014))
            time_vector.extend([cyclical_encode('3002-07-01')]*(season-2014))
            attention_mechanism_vector.extend([1]*(season-2014))

        if (game[1],game[0]) in real_history:
            vector.extend(real_history[(game[1],game[0])])
            time_vector.extend(real_history_dates[(game[1],game[0])])
            attention_mechanism_vector.extend(historical_data_attention[(game[1],game[0])])
        else:
            vector.extend([3]*(season-2014))
            time_vector.extend([cyclical_encode('3002-07-01')]*(season-2014))
            attention_mechanism_vector.extend([1]*(season-2014))

        if (game[1],game[0]) in xg_history:
            vector.extend(xg_history[(game[1],game[0])])
            time_vector.extend(xg_history_dates[(game[1],game[0])])
            attention_mechanism_vector.extend(xg_historical_data_attention[(game[1],game[0])])
        else:
            vector.extend([3]*(season-2014))
            time_vector.extend([cyclical_encode('3002-07-01')]*(season-2014))
            attention_mechanism_vector.extend([1]*(season-2014))
        print(real_history[(game[1],game[0])])
        print(real_history_dates[(game[1],game[0])])
        print(historical_data_attention[(game[1],game[0])])


        #ADD CURRENT FORM
        vector.extend(form_before_game(full_recent_form[game[0]],game_results[game][1])[0])
        time_vector.extend(form_before_game(full_recent_form[game[0]],game_results[game][1])[1])
        attention_mechanism_vector.extend(form_before_game(full_recent_form[game[0]],game_results[game][1])[2])
        print(form_before_game(full_recent_form[game[0]],game_results[game][1])[0])
        print(form_before_game(full_recent_form[game[0]],game_results[game][1])[1])
        print(form_before_game(full_recent_form[game[0]],game_results[game][1])[2])

        vector.extend(form_before_game(home_recent_form[game[0]],game_results[game][1])[0])
        time_vector.extend(form_before_game(home_recent_form[game[0]],game_results[game][1])[1])
        attention_mechanism_vector.extend(form_before_game(home_recent_form[game[0]],game_results[game][1])[2])

        vector.extend(form_before_game(xg_full_recent_form[game[0]],game_results[game][1])[0])
        time_vector.extend(form_before_game(xg_full_recent_form[game[0]],game_results[game][1])[1])
        attention_mechanism_vector.extend(form_before_game(xg_full_recent_form[game[0]],game_results[game][1])[2])

        vector.extend(form_before_game(xg_home_recent_form[game[0]],game_results[game][1])[0])
        time_vector.extend(form_before_game(xg_home_recent_form[game[0]],game_results[game][1])[1])
        attention_mechanism_vector.extend(form_before_game(xg_home_recent_form[game[0]],game_results[game][1])[2])

        vector.extend(form_before_game(full_recent_form[game[1]],game_results[game][1])[0])
        time_vector.extend(form_before_game(full_recent_form[game[1]],game_results[game][1])[1])
        attention_mechanism_vector.extend(form_before_game(full_recent_form[game[1]],game_results[game][1])[2])

        vector.extend(form_before_game(away_recent_form[game[1]],game_results[game][1])[0])
        time_vector.extend(form_before_game(away_recent_form[game[1]],game_results[game][1])[1])
        attention_mechanism_vector.extend(form_before_game(away_recent_form[game[1]],game_results[game][1])[2])

        vector.extend(form_before_game(xg_full_recent_form[game[1]],game_results[game][1])[0])
        time_vector.extend(form_before_game(xg_full_recent_form[game[1]],game_results[game][1])[1])
        attention_mechanism_vector.extend(form_before_game(xg_full_recent_form[game[1]],game_results[game][1])[2])

        vector.extend(form_before_game(xg_away_recent_form[game[1]],game_results[game][1])[0])
        time_vector.extend(form_before_game(xg_away_recent_form[game[1]],game_results[game][1])[1])
        attention_mechanism_vector.extend(form_before_game(xg_away_recent_form[game[1]],game_results[game][1])[2])

        np.array(vector)

        vector_list.append(vector)
        time_vector_list.append(time_vector)
        attention_mechanism_vector_list.append(attention_mechanism_vector)
        # print(vector_list)
        # print(time_vector_list)
        # print(attention_mechanism_vector_list)
        return vector_list,time_vector_list,attention_mechanism_vector_list

def predict_result(model,full_vector_list_scaler,test_vector_list,test_time_vector_list,test_attention_mechanism_vector_list):


    test_vector_list = np.array(test_vector_list)
    test_time_vector_list = np.array(test_time_vector_list)
    # year_features = test_time_vector_list[:, 0].reshape(-1, 1)



    test_vector_list = full_vector_list_scaler.transform(test_vector_list)


    standardized_time_vectors = []
    for time_vector in test_time_vector_list:

        # Extract year from each sample's time vector
        years = np.array([tv[0] for tv in time_vector]).reshape(-1, 1)

        # Standardize years within this specific sample
        standardized_years = scaler.fit_transform(years).flatten()
        # standardized_years = standardized_years_scaler.transform(years).flatten()

        # Replace the year in the original time vector
        for idx, _ in enumerate(time_vector):
            time_vector[idx][0] = standardized_years[idx]

        standardized_time_vectors.append(time_vector)


    test_game_data_2d_list = []
    for i in range(len(test_vector_list)):
        feature_list = test_vector_list[i]
        time_list = standardized_time_vectors[i]

        feature_array = np.array(feature_list)
        feature_array_expanded = np.expand_dims(feature_array, axis=-1)
        time_array = np.array(time_list)

        # game_data_2d = np.stack((feature_array, time_array), axis=-1)
        test_game_data_2d = np.concatenate((feature_array_expanded, time_array), axis=-1)
        test_game_data_2d_list.append(test_game_data_2d)

    seq_len = max(len(item) for item in test_game_data_2d_list)  # Find the maximum sequence length
    d_model = test_game_data_2d_list[0].shape[1]  # Assuming all sequences have the same feature dimension

    # Generate positional encoding matrix
    pos_enc_matrix = positional_encoding(seq_len, d_model)

    # Add positional encoding to each sequence
    test_game_data_2d_list_with_pos = []
    for game_data_2d in test_game_data_2d_list:
        seq_length = game_data_2d.shape[0]
        # Add only the relevant part of the positional encoding
        pos_enc_for_this_seq = pos_enc_matrix[:seq_length, :]
        game_data_2d_with_pos = game_data_2d + pos_enc_for_this_seq.numpy()
        test_game_data_2d_list_with_pos.append(game_data_2d_with_pos)

    game_data_2d_np_array = np.array(test_game_data_2d_list_with_pos)
    # Convert lists to PyTorch tensors
    game_data_2d_tensor = torch.tensor(game_data_2d_np_array, dtype=torch.float)
    # game_data_2d_tensor = torch.tensor(game_data_2d_list_with_pos, dtype=torch.float)
    attention_mask_tensor = torch.tensor(test_attention_mechanism_vector_list, dtype=torch.bool)
    # target_tensor = torch.tensor(test_target_list, dtype=torch.long)
    # print(game_data_2d_tensor.shape)
    # print(attention_mask_tensor.shape)
    # print(target_tensor.shape)

    # # Step 3: Prepare your data
    # # Assuming you have a Dataset class for your data
    # test_dataset = TensorDataset(game_data_2d_tensor, attention_mask_tensor, target_tensor)  # Adjust as necessary
    test_dataset = TensorDataset(game_data_2d_tensor, attention_mask_tensor)  # Adjust as necessary
    # Prepare DataLoader for single-item batches
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

    # for i, (inputs, masks, labels) in enumerate(test_loader):
    for i, (inputs, masks) in enumerate(test_loader):
        # Ensure inputs and masks maintain their batch dimension
        inputs = inputs.squeeze(0)  # Adjust dimensions if necessary
        masks = masks.squeeze(0)  # Adjust dimensions if necessary
        output = model(inputs, masks)

        # Ensure output maintains its batch dimension
        if output.dim() == 1:
            output = output.unsqueeze(0)  # Adds a batch dimension

        probabilities = F.softmax(output, dim=1)
        predicted_class = probabilities.argmax(dim=1)
        return probabilities.squeeze().tolist(),predicted_class.item()

async def predict_game(game,league,season,date,model,full_vector_list_scaler,odds):
    ssl_context = ssl.create_default_context(cafile=certifi.where())
    async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(ssl=ssl_context)) as session:
        understat = Understat(session)
        full_table = await understat.get_league_table(league, season, with_headers=False,h_a='overall',start_date=None, end_date=date)
        home_table = await understat.get_league_table(league, season, with_headers=False,h_a='home',start_date=None, end_date=date)
        away_table = await understat.get_league_table(league, season, with_headers=False,h_a='away',start_date=None, end_date=date)
        home_full_position = 0
        away_full_position = 0
        home_position = 0
        away_position = 0
        for team in full_table:
            home_full_position += 1
            if team[0] == game[0]:
                break
        for team in full_table:
            away_full_position += 1
            if team[0] == game[1]:
                break
        for team in home_table:
            home_position += 1
            if team[0] == game[0]:
                break
        for team in away_table:
            away_position += 1
            if team[0] == game[1]:
                break
        vector_list,time_vector_list,attention_mechanism_vector_list = predict_vector(game,league,season,home_full_position,away_full_position,home_position,away_position,date,odds)
        print(game)

        prob, prediction = predict_result(model,full_vector_list_scaler,vector_list,time_vector_list,attention_mechanism_vector_list)

        print(prob)
        print(prediction)


input_dim = 7  # Assuming [batch_size, seq_len, features]
num_heads = 7  # Example value, adjust as necessary
num_encoder_layers = 3   # Example value
num_classes = 3  # Adjust based on your specific task
# Step 1: Define the model
model = NumericalTransformerModel(input_dim, num_heads, num_encoder_layers, num_classes)  # Replace MyModel with your model's class name

# Step 2: Load the saved model 'best_model_gpu.pth'
# model_load_path = '/home/user/Desktop/GitHub Projects/BettingData/best_model_gpu.pth'
model_load_path = 'best_model_gpu3.pth'
model.load_state_dict(torch.load(model_load_path))
model.eval()
full_vector_list_scaler = load('full_vector_list_scaler.joblib')
with torch.no_grad():
# standardized_years_scaler = load('standardized_years_scaler.joblib')
  await predict_game(('Sheffield United','Brighton'),'EPL',2023,'2024-01-01',model,full_vector_list_scaler,104)
  # await predict_game(('Chelsea','Wolverhampton Wanderers'),'EPL',2023,'2024-02-03',model,full_vector_list_scaler,-700)
  # await predict_game(('Luton','Manchester United'),'EPL',2023,'2024-02-17',model,full_vector_list_scaler,100)
  # await predict_game(('Rayo Vallecano','Real Madrid'),'La Liga',2023,'2024-02-17',model,full_vector_list_scaler,115)
  # await predict_game(('Granada','Almeria'),'La Liga',2023,'2024-02-17',model,full_vector_list_scaler,-334)
  # await predict_game(('Mallorca','Real Sociedad'),'La Liga',2023,'2024-02-17',model,full_vector_list_scaler,-175)
  # await predict_game(('Real Betis','Alaves'),'La Liga',2023,'2024-02-17',model,full_vector_list_scaler,-350)
  # await predict_game(('Freiburg','Eintracht Frankfurt'),'Bundesliga',2023,'2024-02-17',model,full_vector_list_scaler,-250)
  # await predict_game(('Bochum','Bayern Munich'),'Bundesliga',2023,'2024-02-17',model,full_vector_list_scaler,175)
  # await predict_game(('Lazio','Bologna'),'Serie A',2023,'2024-02-17',model,full_vector_list_scaler,-275)
  # await predict_game(('Udinese','Cagliari'),'Serie A',2023,'2024-02-17',model,full_vector_list_scaler,-450)
  # await predict_game(('Empoli','Fiorentina'),'Serie A',2023,'2024-02-17',model,full_vector_list_scaler,-138)
  # await predict_game(('Frosinone','Roma'),'Serie A',2023,'2024-02-17',model,full_vector_list_scaler,-125)
  # await predict_game(('Monza','AC Milan'),'Serie A',2023,'2024-02-17',model,full_vector_list_scaler,100)
  # await predict_game(('Strasbourg','Lorient'),'Ligue 1',2023,'2024-02-17',model,full_vector_list_scaler,-600)
  # await predict_game(('Rennes','Clermont Foot'),'Ligue 1',2023,'2024-02-17',model,full_vector_list_scaler,-700)
  # await predict_game(('Monaco','Toulouse'),'Ligue 1',2023,'2024-02-17',model,full_vector_list_scaler,-700)
  # await predict_game(('Montpellier','Metz'),'Ligue 1',2023,'2024-02-17',model,full_vector_list_scaler,-600)
  # await predict_game(('Reims','Lens'),'Ligue 1',2023,'2024-02-17',model,full_vector_list_scaler,-350)
  # await predict_game(('Brest','Marseille'),'Ligue 1',2023,'2024-02-17',model,full_vector_list_scaler,-275)